{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process, fuzz\n",
    "from rapidfuzz import process, fuzz\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the datasets\n",
    "saudi_data = pd.read_excel(\"Data/SFDAData.xlsx\")\n",
    "usfda_data = pd.read_excel(\"Data/USData/USPoliData.xlsx\")\n",
    "ema_data = pd.read_excel(\"Data/EMAData/EMA_cleaned.xlsx\")\n",
    "UK_data = pd.read_excel(\"Data/UKData/Cleaned_UK.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the saudi and UK data to put _ in the column names where there is a space\n",
    "for col in saudi_data.columns:\n",
    "    if \" \" in col:\n",
    "        saudi_data.rename(columns={col: col.replace(\" \", \"_\")}, inplace=True)\n",
    "\n",
    "for col in UK_data.columns:\n",
    "    if \" \" in col:\n",
    "        UK_data.rename(columns={col: col.replace(\" \", \"_\")}, inplace=True)\n",
    "\n",
    "# rename Approval_Year to be US_Approval_Year\n",
    "usfda_data.rename(columns={\"Approval_Year\": \"US_Approval_Year\"}, inplace=True)\n",
    "\n",
    "# First Approval Date in the UK to be UK_Approval_Year\n",
    "UK_data.rename(columns={\"First_Approval_Date\": \"UK_Approval_Year\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['National_Drug_ID', 'ReferenceNumber', 'Old_register_Number',\n",
      "       'Registration_Year', 'DrugType', 'Sub-Type', 'Scientific_Name',\n",
      "       'Trade_Name', 'Strength', 'StrengthUnit', 'PharmaceuticalForm',\n",
      "       'AdministrationRoute', 'AtcCode1', 'AtcCode2', 'Size', 'SizeUnit',\n",
      "       'PackageTypes', 'PackageSize', 'Legal_Status', 'Product_Control',\n",
      "       'Distribute_area', 'Public_price', 'Marketing_Company',\n",
      "       'Marketing_Country', 'Manufacture_Name', 'Manufacture_Country',\n",
      "       'Secondry_package__manufacture', 'Main_Agent', 'Secosnd_Agent',\n",
      "       'Third_agent', 'Description_Code', 'Authorization_Status',\n",
      "       'International_Drug_ID', 'POL_Brand_Name', 'POL_Company_(Parent)',\n",
      "       'POL_Dosage_Form', 'POL_Strength_Comment', 'POL_Company_(Subsidiary)',\n",
      "       'POL_Drug_Type', 'POL_Hospital_Status', 'POL_Parallel_Import',\n",
      "       'EMA_Brand_ID', 'POL_Therapy_Area_/_Indication', 'POL_ATC_Code',\n",
      "       'POL_First_Price_Date', 'POL_First_Price_(LCU)',\n",
      "       'POL_First_Price_%_Change', 'POL_Ex-manufacturer_Price_(USD)',\n",
      "       'POL_Wholesale_Price_(USD)', 'POL_Retail_Price_(USD)',\n",
      "       'POL_DDD_Cost_(LCU)', 'POL_Defined_Daily_Dose_(DDD)',\n",
      "       'POL_Price_Per_Unit_(LCU)', 'POL_Price_Comment',\n",
      "       'POL_Withdrawn/Not_launched', 'POL_Exchange_Rate_(LCU_to_USD)',\n",
      "       'POL_First_Price_Change_Date'],\n",
      "      dtype='object')\n",
      "Index(['National_Drug_ID', 'International_Drug_ID', 'Brand_Name', 'Applicant',\n",
      "       'Generic_Name', 'Dosage_Form', 'ISO_Code', 'Strength_Value',\n",
      "       'Strength_Unit', 'Strength_Comment', 'Number_of_Units', 'Volume',\n",
      "       'Volume_Units', 'Dose', 'Dose_Unit', 'Ex-manufacturer_Price_(LCU)',\n",
      "       'Company_(Subsidiary)', 'Drug_Type', 'EMA_Brand_ID',\n",
      "       'Therapy_Area_/_Indication', 'ATC_Code', 'US_Approval_Year',\n",
      "       'Strength'],\n",
      "      dtype='object')\n",
      "Index(['Category', 'Brand_Name', 'EMA_Brand_ID', 'Medicine_status',\n",
      "       'Opinion_status', 'Latest_procedure_affecting_product_information',\n",
      "       'INN_Common_Name', 'Generic_Name', 'Therapeutic_area_(MeSH)',\n",
      "       'Patient_safety', 'ATC_Code', 'Pharmacotherapeutic_group\\n(human)',\n",
      "       'Therapeutic_indication', 'Accelerated_assessment',\n",
      "       'Additional_monitoring', 'Advanced_therapy', 'Biosimilar',\n",
      "       'Conditional_approval', 'Exceptional_circumstances',\n",
      "       'Generic_or_hybrid', 'Orphan_medicine', 'PRIME:_priority_medicine',\n",
      "       'Applicant', 'European_Commission_decision_date',\n",
      "       'Opinion_adopted_date', 'Withdrawal_of_application_date',\n",
      "       'EMA_Approval_Year', 'Refusal_of_marketing_authorisation_date',\n",
      "       'Withdrawal_/_expiry_/_revocation_/_lapse_of_marketing_authorisation_date',\n",
      "       'Revision_number', 'First_published_date', 'Last_updated_date',\n",
      "       'Medicine_URL'],\n",
      "      dtype='object')\n",
      "Index(['National_Drug_ID', 'International_Drug_ID', 'Brand_Name',\n",
      "       'Company_(Parent)', 'Company_(Subsidiary)', 'Generic_Name',\n",
      "       'Dosage_Form', 'Strength_Value', 'Strength_Unit', 'Strength_Comment',\n",
      "       'Number_of_Units', 'Volume', 'Volume_Units',\n",
      "       'Ex-manufacturer_Price_(LCU)', 'Wholesale_Price_(LCU)',\n",
      "       'Retail_Price_(LCU)', 'Orphan_Drug_Designation', 'Drug_Type',\n",
      "       'EMA_Brand_ID', 'Therapy_Area_/_Indication', 'ATC_Code',\n",
      "       'Regulatory_Submission_Date', 'UK_Approval_Year', 'Launch_Date',\n",
      "       'First_Price_Date', 'Ex-manufacturer_Price_(USD)',\n",
      "       'Wholesale_Price_(USD)', 'Retail_Price_(USD)', 'DDD_Cost_(LCU)',\n",
      "       'Defined_Daily_Dose_(DDD)', 'Price_Per_Unit_(LCU)', 'Price_Date',\n",
      "       'Withdrawn/Not_launched', 'Withdrawn/Not_launched_Comment',\n",
      "       'Level_of_Reimbursement'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# show column names\n",
    "print(saudi_data.columns)\n",
    "print(usfda_data.columns)\n",
    "print(ema_data.columns)\n",
    "print(UK_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert US_Approval_Year to datetime and extract the year\n",
    "usfda_data[\"US_Approval_Year\"] = pd.to_datetime(\n",
    "    usfda_data[\"US_Approval_Year\"], format=\"%Y\", errors=\"coerce\"\n",
    ").dt.year\n",
    "\n",
    "# Convert UK_Approval_Year to datetime and extract the year\n",
    "UK_data[\"UK_Approval_Year\"] = pd.to_datetime(\n",
    "    UK_data[\"UK_Approval_Year\"], errors=\"coerce\"\n",
    ").dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any rows in the usfdadata where the US_Approval_Year is 1900\n",
    "usfda_data = usfda_data[usfda_data.US_Approval_Year != 1900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in Saudi Arabia dataset:  1108\n",
      "Total rows in US FDA dataset:  27914\n",
      "Total rows in EMA dataset:  2105\n",
      "Total rows in UK dataset:  4784\n"
     ]
    }
   ],
   "source": [
    "# total of rows in each dataset\n",
    "print(\"Total rows in Saudi Arabia dataset: \", len(saudi_data))\n",
    "print(\"Total rows in US FDA dataset: \", len(usfda_data))\n",
    "print(\"Total rows in EMA dataset: \", len(ema_data))\n",
    "print(\"Total rows in UK dataset: \", len(UK_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in Saudi Arabia dataset with EMA_Brand_ID:  647\n"
     ]
    }
   ],
   "source": [
    "# how many had EMA_Bran_ID in the saudi data?\n",
    "print(\n",
    "    \"Total rows in Saudi Arabia dataset with EMA_Brand_ID: \",\n",
    "    len(saudi_data[saudi_data[\"EMA_Brand_ID\"].notnull()]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Match with EMA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a left merge to add EMA_Approval_Year to saudi_data based on EMA_Brand_ID\n",
    "saudi_data = pd.merge(\n",
    "    saudi_data,\n",
    "    ema_data[[\"EMA_Brand_ID\", \"EMA_Approval_Year\"]],\n",
    "    on=\"EMA_Brand_ID\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645\n"
     ]
    }
   ],
   "source": [
    "# how many rows have been merged between saudi and EMA data (how many EMA years added)\n",
    "print(saudi_data[\"EMA_Approval_Year\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Match with US\n",
    "\n",
    "2 uniqe identifiers exist but they need cleaning before merging with the Saudi Data. Given the volume of th data, we'll only work with those who have non missing for either of these identifiers. \n",
    "\n",
    "Upon inspection, looks like we have many duplicates by International_Drug_ID and EMA_Brand_ID in the data. We'll drop any duplicates by International_Drug_ID or EMA_Brand_ID that have the same US_Approval_Year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in US FDA dataset with International_Drug_ID:  2738\n",
      "Total rows in US FDA dataset with EMA_Brand_ID:  2605\n"
     ]
    }
   ],
   "source": [
    "# how many in the usfda_data have International_Drug_ID and how many have EMA_Brand_ID?\n",
    "print(\n",
    "    \"Total rows in US FDA dataset with International_Drug_ID: \",\n",
    "    len(usfda_data[usfda_data[\"International_Drug_ID\"].notnull()]),\n",
    ")\n",
    "print(\n",
    "    \"Total rows in US FDA dataset with EMA_Brand_ID: \",\n",
    "    len(usfda_data[usfda_data[\"EMA_Brand_ID\"].notnull()]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## First inspect data and duplicates before merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates by the international drug ID in the saudi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep rows that have either International_Drug_ID or EMA_Brand_ID in the usfda_data\n",
    "usfda_data = usfda_data[\n",
    "    usfda_data[\"International_Drug_ID\"].notnull() | usfda_data[\"EMA_Brand_ID\"].notnull()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicates in Saudi Arabia dataset by International Drug ID:  346\n",
      "Total duplicates in Saudi Arabia dataset by International Drug ID and Registration Year:  336\n",
      "761\n"
     ]
    }
   ],
   "source": [
    "# How many duplicates by the International_Drug_ID in the saudi data\n",
    "print(\n",
    "    \"Total duplicates in Saudi Arabia dataset by International Drug ID: \",\n",
    "    saudi_data.duplicated(subset=\"International_Drug_ID\").sum(),\n",
    ")\n",
    "\n",
    "# how many of the duplicates also have the same Registration_Year\n",
    "print(\n",
    "    \"Total duplicates in Saudi Arabia dataset by International Drug ID and Registration Year: \",\n",
    "    saudi_data.duplicated(subset=[\"International_Drug_ID\", \"Registration_Year\"]).sum(),\n",
    ")\n",
    "print(saudi_data[\"International_Drug_ID\"].nunique())\n",
    "\n",
    "\n",
    "# convert the International_Drug_ID to string in both saudi and usfda data\n",
    "saudi_data[\"International_Drug_ID\"] = saudi_data[\"International_Drug_ID\"].astype(str)\n",
    "usfda_data[\"International_Drug_ID\"] = usfda_data[\"International_Drug_ID\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in US FDA dataset with EMA_Brand_ID:  2605\n",
      "Total rows in US FDA dataset with International_Drug_ID:  3672\n",
      "Total rows in US FDA dataset with EMA_Brand_ID but not International_Drug_ID:  0\n",
      "Total rows in US FDA dataset with International_Drug_ID but not EMA_Brand_ID:  1067\n"
     ]
    }
   ],
   "source": [
    "# How many have ema_brand_id in the usfda_data?\n",
    "print(\n",
    "    \"Total rows in US FDA dataset with EMA_Brand_ID: \",\n",
    "    len(usfda_data[usfda_data[\"EMA_Brand_ID\"].notnull()]),\n",
    ")\n",
    "\n",
    "# How many have International_Drug_ID in the usfda_data?\n",
    "print(\n",
    "    \"Total rows in US FDA dataset with International_Drug_ID: \",\n",
    "    len(usfda_data[usfda_data[\"International_Drug_ID\"].notnull()]),\n",
    ")\n",
    "\n",
    "\n",
    "# how many have ema_brand_id but not International_Drug_ID in the usfda_data?\n",
    "print(\n",
    "    \"Total rows in US FDA dataset with EMA_Brand_ID but not International_Drug_ID: \",\n",
    "    len(\n",
    "        usfda_data[\n",
    "            (usfda_data[\"EMA_Brand_ID\"].notnull())\n",
    "            & (usfda_data[\"International_Drug_ID\"].isnull())\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# how many have International_Drug_ID but not ema_brand_id in the usfda_data?\n",
    "print(\n",
    "    \"Total rows in US FDA dataset with International_Drug_ID but not EMA_Brand_ID: \",\n",
    "    len(\n",
    "        usfda_data[\n",
    "            (usfda_data[\"International_Drug_ID\"].notnull())\n",
    "            & (usfda_data[\"EMA_Brand_ID\"].isnull())\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique International_Drug_ID in US FDA dataset:  2170\n",
      "Total unique EMA_Brand_ID in US FDA dataset:  687\n"
     ]
    }
   ],
   "source": [
    "# how many uniqe International_Drug_ID in the usfda_data\n",
    "print(\n",
    "    \"Total unique International_Drug_ID in US FDA dataset: \",\n",
    "    len(usfda_data[\"International_Drug_ID\"].unique()),\n",
    ")\n",
    "\n",
    "# how many uniqe EMA_Brand_ID in the usfda_data\n",
    "print(\n",
    "    \"Total unique EMA_Brand_ID in US FDA dataset: \",\n",
    "    len(usfda_data[\"EMA_Brand_ID\"].unique()),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in US FDA dataset that are duplicates by International_Drug_ID that have the same US_Approval_Year:  1682\n",
      "Total rows in US FDA dataset that are duplicates by EMA_Brand_ID that have the same US_Approval_Year:  3429\n"
     ]
    }
   ],
   "source": [
    "# How many in the usfda_data are duplicates by International_Drug_ID and EMA_Brand_ID\n",
    "# and also happen to have the same US_Approval_Year?\n",
    "\n",
    "usfda_data[\"International_Drug_ID\"] = usfda_data[\"International_Drug_ID\"].str.strip()\n",
    "usfda_data[\"EMA_Brand_ID\"] = usfda_data[\"EMA_Brand_ID\"].str.strip()\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Total rows in US FDA dataset that are duplicates by International_Drug_ID that have the same US_Approval_Year: \",\n",
    "    len(\n",
    "        usfda_data[\n",
    "            usfda_data.duplicated(\n",
    "                subset=[\"International_Drug_ID\", \"US_Approval_Year\"], keep=False\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Total rows in US FDA dataset that are duplicates by EMA_Brand_ID that have the same US_Approval_Year: \",\n",
    "    len(\n",
    "        usfda_data[\n",
    "            usfda_data.duplicated(\n",
    "                subset=[\"EMA_Brand_ID\", \"US_Approval_Year\"], keep=False\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the merge after dropping the duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column 1: Based on `International_Drug_ID`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below method keeps only one version for those with the same International ID and Year. as for those with International ID dueps but diffrent approval years, they will be concatenated in one cell. this is ideal for when we don't won't to drop any valueable info during automation untill we douple check later. we have 212 of those dupes with diffrent years that remain undropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique drugs after grouping by International_Drug_ID: 2170\n"
     ]
    }
   ],
   "source": [
    "# Drop exact duplicates based on International_Drug_ID and US_Approval_Year\n",
    "uniqe_international_usfda_data = usfda_data.drop_duplicates(\n",
    "    subset=[\"International_Drug_ID\", \"US_Approval_Year\"], keep=\"first\"\n",
    ")\n",
    "\n",
    "# Group by International_Drug_ID and concatenate approval years into a single entry\n",
    "uniqe_international_usfda_data = uniqe_international_usfda_data.groupby(\n",
    "    \"International_Drug_ID\", as_index=False\n",
    ").agg(\n",
    "    {\n",
    "        \"US_Approval_Year\": lambda x: \", \".join(\n",
    "            map(str, sorted(set(x)))\n",
    "        )  # Joins years into one entry\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ensure US_Approval_Year is a clean string (removes unnecessary spaces)\n",
    "uniqe_international_usfda_data[\"US_Approval_Year\"] = (\n",
    "    uniqe_international_usfda_data[\"US_Approval_Year\"].astype(str).str.strip()\n",
    ")\n",
    "\n",
    "# Check how many unique drug IDs remain\n",
    "print(\n",
    "    \"Total unique drugs after grouping by International_Drug_ID:\",\n",
    "    uniqe_international_usfda_data.shape[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip spaces from 'International_Drug_ID' in both datasets\n",
    "uniqe_international_usfda_data[\"International_Drug_ID\"] = (\n",
    "    uniqe_international_usfda_data[\"International_Drug_ID\"].str.strip()\n",
    ")\n",
    "saudi_data[\"International_Drug_ID\"] = saudi_data[\"International_Drug_ID\"].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final check before performing the merge!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in uniqe_international_usfda_data after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_check = uniqe_international_usfda_data.duplicated(\n",
    "    subset=[\"International_Drug_ID\"], keep=False\n",
    ").sum()\n",
    "print(f\"Duplicates in uniqe_international_usfda_data after cleaning: {duplicate_check}\")\n",
    "\n",
    "### PERFECT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a left merge to add US Approval Year to the Saudi Data based on International_Drug_ID\n",
    "saudi_data = pd.merge(\n",
    "    saudi_data,\n",
    "    uniqe_international_usfda_data[[\"International_Drug_ID\", \"US_Approval_Year\"]],\n",
    "    on=\"International_Drug_ID\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "saudi_data = saudi_data.rename(\n",
    "    columns={\"US_Approval_Year\": \"US_Approval_Year_International\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column 2: Based on `EMA_Brand_ID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique drugs after grouping by EMA_Brand_ID: 686\n"
     ]
    }
   ],
   "source": [
    "# Drop exact duplicates based on EMA_ID and US_Approval_Year\n",
    "uniqe_EMAID_usfda_data = usfda_data.drop_duplicates(\n",
    "    subset=[\"EMA_Brand_ID\", \"US_Approval_Year\"], keep=\"first\"\n",
    ")\n",
    "\n",
    "# Group by EMA ID and concatenate approval years into a single entry\n",
    "uniqe_EMAID_usfda_data = uniqe_EMAID_usfda_data.groupby(\n",
    "    \"EMA_Brand_ID\", as_index=False\n",
    ").agg(\n",
    "    {\n",
    "        \"US_Approval_Year\": lambda x: \", \".join(\n",
    "            map(str, sorted(set(x)))\n",
    "        )  # Joins years into one entry\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ensure US_Approval_Year is a clean string (removes unnecessary spaces)\n",
    "uniqe_EMAID_usfda_data[\"US_Approval_Year\"] = (\n",
    "    uniqe_EMAID_usfda_data[\"US_Approval_Year\"].astype(str).str.strip()\n",
    ")\n",
    "\n",
    "# Check how many unique drug IDs remain\n",
    "print(\n",
    "    \"Total unique drugs after grouping by EMA_Brand_ID:\",\n",
    "    uniqe_EMAID_usfda_data.shape[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a left merge to add US Approval Year to saudi_data based on EMA_Brand_ID\n",
    "saudi_data = pd.merge(\n",
    "    saudi_data,\n",
    "    uniqe_EMAID_usfda_data[[\"EMA_Brand_ID\", \"US_Approval_Year\"]],\n",
    "    on=\"EMA_Brand_ID\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "saudi_data = saudi_data.rename(columns={\"US_Approval_Year\": \"US_Approval_Year_EMA\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Match with UK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll repeat the same methods we did for the US data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep rows that have either International_Drug_ID or EMA_Brand_ID in the usfda_data\n",
    "UK_data = UK_data[\n",
    "    UK_data[\"International_Drug_ID\"].notnull() | UK_data[\"EMA_Brand_ID\"].notnull()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in US FDA dataset with International_Drug_ID:  2714\n",
      "Total rows in US FDA dataset with EMA_Brand_ID:  2311\n"
     ]
    }
   ],
   "source": [
    "# how many in the UK data have International_Drug_ID and how many have EMA_Brand_ID?\n",
    "print(\n",
    "    \"Total rows in US FDA dataset with International_Drug_ID: \",\n",
    "    len(UK_data[UK_data[\"International_Drug_ID\"].notnull()]),\n",
    ")\n",
    "print(\n",
    "    \"Total rows in US FDA dataset with EMA_Brand_ID: \",\n",
    "    len(UK_data[UK_data[\"EMA_Brand_ID\"].notnull()]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string and remove and leading or trailing spaces\n",
    "UK_data[\"International_Drug_ID\"] = UK_data[\"International_Drug_ID\"].astype(str)\n",
    "UK_data[\"EMA_Brand_ID\"] = UK_data[\"EMA_Brand_ID\"].astype(str)\n",
    "\n",
    "\n",
    "UK_data[\"International_Drug_ID\"] = UK_data[\"International_Drug_ID\"].str.strip()\n",
    "UK_data[\"EMA_Brand_ID\"] = UK_data[\"EMA_Brand_ID\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in UK dataset that are duplicates by International_Drug_ID that have the same UK_Approval_Year:  0\n",
      "Total rows in UK dataset that are duplicates by EMA_Brand_ID that have the same UK_Approval_Year:  2310\n"
     ]
    }
   ],
   "source": [
    "# How many in the UK data are duplicates by International_Drug_ID and EMA_Brand_ID\n",
    "# and also happen to have the same UK_Approval_Year?\n",
    "\n",
    "print(\n",
    "    \"Total rows in UK dataset that are duplicates by International_Drug_ID that have the same UK_Approval_Year: \",\n",
    "    len(\n",
    "        UK_data[\n",
    "            UK_data.duplicated(\n",
    "                subset=[\"International_Drug_ID\", \"UK_Approval_Year\"], keep=False\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Total rows in UK dataset that are duplicates by EMA_Brand_ID that have the same UK_Approval_Year: \",\n",
    "    len(\n",
    "        UK_data[\n",
    "            UK_data.duplicated(subset=[\"EMA_Brand_ID\", \"UK_Approval_Year\"], keep=False)\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the merge after dropping the duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column 1: Based on `International_Drug_ID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique drugs after grouping by International_Drug_ID: 2709\n"
     ]
    }
   ],
   "source": [
    "# Drop exact duplicates based on International_Drug_ID and UK_Approval_Year\n",
    "uniqe_international_UK_data = UK_data.drop_duplicates(\n",
    "    subset=[\"International_Drug_ID\", \"UK_Approval_Year\"], keep=\"first\"\n",
    ")\n",
    "\n",
    "# Group by International_Drug_ID and concatenate approval years into a single entry\n",
    "uniqe_international_UK_data = uniqe_international_UK_data.groupby(\n",
    "    \"International_Drug_ID\", as_index=False\n",
    ").agg(\n",
    "    {\n",
    "        \"UK_Approval_Year\": lambda x: \", \".join(\n",
    "            map(str, sorted(set(x)))\n",
    "        )  # Joins years into one entry\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ensure UK_Approval_Year is a clean string (removes unnecessary spaces)\n",
    "uniqe_international_UK_data[\"UK_Approval_Year\"] = (\n",
    "    uniqe_international_UK_data[\"UK_Approval_Year\"].astype(str).str.strip()\n",
    ")\n",
    "\n",
    "# Check how many unique drug IDs remain\n",
    "print(\n",
    "    \"Total unique drugs after grouping by International_Drug_ID:\",\n",
    "    uniqe_international_UK_data.shape[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip spaces from 'International_Drug_ID' in both datasets\n",
    "uniqe_international_UK_data[\"International_Drug_ID\"] = uniqe_international_UK_data[\n",
    "    \"International_Drug_ID\"\n",
    "].str.strip()\n",
    "saudi_data[\"International_Drug_ID\"] = saudi_data[\"International_Drug_ID\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in uniqe_international_usfda_data after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_check2 = uniqe_international_UK_data.duplicated(\n",
    "    subset=[\"International_Drug_ID\"], keep=False\n",
    ").sum()\n",
    "print(f\"Duplicates in uniqe_international_usfda_data after cleaning: {duplicate_check}\")\n",
    "\n",
    "### PERFECT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a left merge to add International_Drug_ID to saudi_data based on International_Drug_ID\n",
    "saudi_data = pd.merge(\n",
    "    saudi_data,\n",
    "    uniqe_international_UK_data[[\"International_Drug_ID\", \"UK_Approval_Year\"]],\n",
    "    on=\"International_Drug_ID\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "saudi_data = saudi_data.rename(\n",
    "    columns={\"UK_Approval_Year\": \"UK_Approval_Year_International\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column 2: Based on `EMA_Brand_ID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique drugs after grouping by EMA_Brand_ID: 947\n"
     ]
    }
   ],
   "source": [
    "# Drop exact duplicates based on EMA_ID and UK_Approval_Year\n",
    "uniqe_EMAID_UK_data = UK_data.drop_duplicates(\n",
    "    subset=[\"EMA_Brand_ID\", \"UK_Approval_Year\"], keep=\"first\"\n",
    ")\n",
    "\n",
    "# Group by EMA ID and concatenate approval years into a single entry\n",
    "uniqe_EMAID_UK_data = uniqe_EMAID_UK_data.groupby(\"EMA_Brand_ID\", as_index=False).agg(\n",
    "    {\n",
    "        \"UK_Approval_Year\": lambda x: \", \".join(\n",
    "            map(str, sorted(set(x)))\n",
    "        )  # Joins years into one entry\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ensure UK_Approval_Year is a clean string (removes unnecessary spaces)\n",
    "uniqe_EMAID_UK_data[\"UK_Approval_Year\"] = (\n",
    "    uniqe_EMAID_UK_data[\"UK_Approval_Year\"].astype(str).str.strip()\n",
    ")\n",
    "\n",
    "# Check how many unique drug IDs remain\n",
    "print(\n",
    "    \"Total unique drugs after grouping by EMA_Brand_ID:\", uniqe_EMAID_UK_data.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a left merge to add EMA UK year to saudi_data based on EMA_Brand_ID\n",
    "saudi_data = pd.merge(\n",
    "    saudi_data,\n",
    "    uniqe_EMAID_UK_data[[\"EMA_Brand_ID\", \"UK_Approval_Year\"]],\n",
    "    on=\"EMA_Brand_ID\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "saudi_data = saudi_data.rename(columns={\"UK_Approval_Year\": \"UK_Approval_Year_EMA\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find out how may we matched over all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows without any approval years: 134\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows that don't have any of the specified approval years\n",
    "missing_approval_years = saudi_data[\n",
    "    saudi_data[\"EMA_Approval_Year\"].isnull()\n",
    "    & saudi_data[\"US_Approval_Year_International\"].isnull()\n",
    "    & saudi_data[\"US_Approval_Year_EMA\"].isnull()\n",
    "    & saudi_data[\"UK_Approval_Year_International\"].isnull()\n",
    "    & saudi_data[\"UK_Approval_Year_EMA\"].isnull()\n",
    "]\n",
    "\n",
    "# Print the number of such rows\n",
    "print(\"Number of rows without any approval years:\", len(missing_approval_years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to store the fuzzy matching results\n",
    "saudi_data[\"fuzzy_matched\"] = None\n",
    "\n",
    "# Now iterate through the Saudi data and perform fuzzy matching with US data\n",
    "for index, saudi_row in saudi_data.iterrows():\n",
    "    best_match = None\n",
    "    highest_score = 0\n",
    "\n",
    "    for _, us_row in usfda_data.iterrows():\n",
    "        # Combine the fields for comparison\n",
    "        saudi_combined = f\"{saudi_row['Brand_Name']} {saudi_row['Strength']} {saudi_row['Applicant']}\"\n",
    "        us_combined = (\n",
    "            f\"{us_row['Brand_Name']} {us_row['Strength']} {us_row['Applicant']}\"\n",
    "        )\n",
    "\n",
    "        # Calculate the fuzzy match score\n",
    "        score = fuzz.token_sort_ratio(saudi_combined, us_combined)\n",
    "\n",
    "        # Update the best match if the score is higher\n",
    "        if score > highest_score:\n",
    "            highest_score = score\n",
    "            best_match = us_row[\"US_Approval_Year\"]\n",
    "\n",
    "    # Add the best match to the new column if the score is above a threshold\n",
    "    saudi_data.at[index, \"fuzzy_matched\"] = best_match if highest_score > 80 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows where fuzzy_matched is not null\n",
    "fuzzy_matched_count = saudi_data[\"fuzzy_matched\"].notnull().sum()\n",
    "\n",
    "# Print the count\n",
    "print(\"Number of rows fuzzy matched:\", fuzzy_matched_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only 134 out of 1108 have no match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the saudi data to a new excel file\n",
    "saudi_data.to_excel(\"Data/Merged_Data.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
